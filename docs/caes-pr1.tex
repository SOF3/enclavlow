\documentclass[a4paper, 12pt]{article}
\usepackage[top=0.8in, bottom=0.8in, left=0.5in, right=0.5in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[document]{ragged2e}
\usepackage[pdf]{graphviz}
\usepackage[bookmarksopen=true, hidelinks]{hyperref}
\usepackage{bookmark}
\bookmarksetup{numbered}
% \hypersetup{colorlinks, linkcolor={black}}
\usepackage{cite}
\usepackage{listings}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{soul}
\usepackage{fontspec}
\setmainfont{TeX Gyre Termes}
\usepackage{sourcecodepro}

\title{Data flow analysis for Uranus applications}
\author{Chan Kwan Yin (3035466978)}
\date{28 October 2020}

\lstdefinestyle{j}{
	keywordstyle=\textbf,
	basicstyle=\ttfamily\footnotesize,
	tabsize=4,
	numbers=left,
}

\def\pname{\emph{enclavlow}}

\definecolor{code}{rgb}{0.95, 0.95, 0.95}
\sethlcolor{code}
\def\code#1{\colorbox{code}{\texttt{\footnotesize #1}}}

\begin{document}
\begin{titlepage}
	\begin{center}
		\vspace*{2em}
		\LARGE
		CAES9542 Progress Report 1

		\vspace*{1em}
		\Huge
		\textbf{Data flow analysis for Uranus applications}

		\Large
		\vspace{1.5em}
		\textbf{Chan Kwan Yin (3035466978)}

		\vspace{0.5em}
		28 October 2020
	\end{center}
\end{titlepage}

\thispagestyle{empty}
\begin{abstract}
	Trusted Execution Environments (TEE) protect applications from privileged attacks
	running on untrusted systems such as public clouds,
	but partitioning enclave boundaries is not always a trivial task.
	Partitions too small would leak data to the untrusted host system,
	while partitions too huge would result in unnecessarily large trusted computing base (TCB)
	that increases the risk of overflowing Enclave Page Cache (EPC).
	A passive analysis approach can be adopted where
	users annotate data as sensitive sources or sinks,
	and an analysis tool determines variables considered sensitive
	and compares it with the enclave boundaries declared.

	This project introduces \pname{}, an information flow analysis tool
	for JVM-based projects using Intel SGX enclaves with the Uranus
	\footnote{ Uranus: Simple, Efficient SGX Programming and its Applications.
	\url{https://doi.org/10.1145/3320269.3384763}
	} framework.
	It implements a set of security policies tailored for Uranus-based applications,
	and reports leaking variables or functions that could be run out of enclave.
	The analysis tool is delivered as a Gradle plugin
	to be deployed as a continuous integration tool in Gradle-based projects.
	The source code for \pname{} is released on \url{https://github.com/SOF3/enclavlow}.
\end{abstract}
\newpage

\thispagestyle{empty}
\tableofcontents
\listoffigures
\listoftables
\lstlistoflistings

\setcounter{page}0
\newpage

\section{Abbreviations}
\paragraph{3AC} Three-address Code
\paragraph{CLI} Command Line Interface
\paragraph{DTA} Dynamic Taint Analysis
\paragraph{EPC} Enclave Page Cache
\paragraph{GIGO} Garbage In, Garbage Out
\paragraph{JNI} Java Native Interface
\paragraph{JVM} Java Virtual Machine
\paragraph{OOP} Object-oriented Programming
\paragraph{SGX} Software Guard Extension
\paragraph{TEE} Trusted Execution Environment

\setlength\parskip{1.3em}

\section{Introduction}
\subsection{Background}
With the rise of third-party public cloud servics
such as AWS \cite{aws} and Microsoft Azure \cite{azure},
there is increasing demand for trusted execution where
applications are protected from
attackers with privileged access to the hardware or software.
Modern hardware offer TEE technologies,
such as SGX in Intel CPUs,
with which trusted execution code and sensitive data
are processed in secure "enclaves",
which is protected at hardware level to prevent access
from other hardware or software layers.

One significant application of TEEs is in big data processing,
where confidential user data are processed,
and protection from cloud providers may be necessary
for complianc with privacy regulations such as GDPR \cite{gdpr}.
However, a significant subset of such applications are written
using languages that use JVM as the runtime,
such as Hadoop \cite{apachehadoop} and Spark \cite{apachespark}
Recently, Uranus, a system for
writing SGX applications in Java languages, was released \cite{uranus}.
It provides simple interface for SGX,
where users annotate methods with \code{@JECall} and \code{@JOCall}
to move control flow into or out of enclaves.
It is the responsibility of the user to determine the correct positions
for the \code{@JECall} and \code{@JOCall} annotations,
namely the enclave boundary partitioning".
Since JVM, compared to native applications running on the CPU,
involves an entirely different approach
with regard to software development and distribution,
the tools applicable for native applications are mostly incompatible with JVM,
introducing the corresponding new research areas.

Running the whole application within an SGX enclave is undesirable for two reasons.
First, this violates the principle of least privilege,
where the whole application becomes possible attack surface
for adversaries to compromise protected data \cite{glamdring}.
Second, this implies all memory used by the application
are placed in the enclave memory (the EPC),
which is restricted to 100 MB before significant performance degrading
("1,000X slowdown compared to regular OS paging") \cite{uranus}.
On the other hand, if the enclave is smaller than necessary,
adversaries can either obtain sensitive data directly or
infer sensitive characteristics of them indirectly.

This project presents \pname{}
\footnote{"enclavlow" is a new term coined from the words "enclave" and "flow".},
an information flow analysis tool
for identifying data leak from enclaves.
The user first annotates variables as \code{@Source} and \code{@Sink}.
The tool performs information flow analysis from \code{@Source} variables,
identifying the ways that data from such variables are leaked
to the system outside the executing enclave
without first passing through a \code{@Sink} variable.
The tool compiles a report in HTML format that summarizes the following:
\begin{itemize}
	\item \textbf{Data leak}:
		The report displays the lines of code on which sensitive data are moved
		into areas accessible by privileged adversaries.
		It demonstrates the path from the \code{@Source} variable to the point of leak.
	\item \textbf{Redundant protection}:
		The report lists the functions that could not hold any sensitive data in its local variables,
		hence should be moved out of the enclave partition.
\end{itemize}

\pname{} is shipped as a Gradle plugin,
providing a Gradle task that
takes the \code{*.class} files compiled in the \code{classes} task
and generates the report for the analysis from those classes.

\subsection{Prior art}
Information flow analysis is not a new technology in the field.
While this project analyzes JVM code using SGX enclaves,
prior research on \emph{native} code \emph{automatic partition} was found.

Glamdring \cite{glamdring} is a C framework that
automatically selects the minimal SGX enclave boundaries
based on user requirements specified through C pragma directives.
However, since the process is fully automated,
it has a lower tolerance of false positives,
which increases the risk of unintentional data leak.
This project, unlike Glamdring, will only perform analysis but not automatic partitioning,
allowing for greater false positive tolerance.

Phosphor \cite{BellJonathan2014Pidd} is a DTA framework
that modifies Java bytecode to add tags to sensitive data at runtime
and check if such tags are leaked.
Although dynamic taint is more accurate,
this project prefers a static analysis approach,
which enables developers to identify sensitive regions at compile time
without the need to feed concrete data into methods.

\section{Objectives}
This section describes the usage and precise behaviour of \pname{}.

\subsection{Annotation API}
The \code{enclavlow-api} Gradle submodule in the project
is a \code{compileOnly} library exposing two annotations:

\begin{lstlisting}[style=j, language=java, caption={Definition of @Source and @Sink}]
@Target(AnnotationTarget.LOCAL_VARIABLE)
@Retention(RetentionPolicy.BINARY)
public @interface Source {}

@Target({AnnotationTarget.LOCAL_VARIABLE, AnnotationTarget.METHOD})
@Retention(RetentionPolicy.BINARY)
public @interface Sink {}
\end{lstlisting}

Users should mark \emph{ultimate} data source variables as \code{@Source},
and mark \emph{acceptable} leaks as \code{@Sink}.
The \code{@Sink} annotation, when applied on methods,
is merely a shortcut to assign return values to a \code{@Sink} variables first.
Such shortcut does not apply for throw expressions,
because throwing sensitive data is a rare use case,
has a wide range of scenarios
and highly depends on the exact class thrown.
Genuine throw sinks should use a more verbose syntax of \code{catch}ing the exception,
assigning to a local \code{@Sink} variable and throwing the local variable.

\code{@Sink} can also be used to explicitly suppress false positives generated by \pname{}.

A simple example usage is as below:

\begin{lstlisting}[style=j, language=java, label={lst:SourceSinkExample},
caption={Simple example of @Source and @Sink}]
@JECall
@Sink
int getSum(byte[] encrypted) {
	List<Integer> raw = parse(encrypted);
	return computeSum(raw);
}

List<Integer> parse(byte[] encrypted) {
	@Source byte[] buf = PRIVATE_KEY.decrypt(encrypted);
	List<Integer> result = new ArrayList<>();
	for(byte i : buf) {
		result.add((int) i);
	}
	return result;
}

int computeSum(List<Integer> integers) {
	int sum = 0;
	for(int i : integers) {
		sum += i;
	}
	return sum;
}
\end{lstlisting}

Attention to be given to the following points:
\begin{itemize}
	\item On line 4, \code{raw} is \emph{not} marked \code{@Source}.
		This is because parsing is a late stage after raw data extraction,
		and \code{@Source} should only be applied on the ultimate source.
	\item Line 5 and line 2 altogether assert that
		"computing the sum of \code{raw} is a legitimate leak".
	\item On line 8, \code{parse} is not marked \code{@Sink},
		because the leak of sensitive information should be analyzed.
	\item On line 17, \code{computeSum} is not marked \code{@Sink}.
		This is because it is a sensitivity-neutral utility function
		that does not imply any assertion on whether the leak is acceptable.
		Otherwise, if line 12 is changed to Listing \ref{lst:computeSum},
		\code{parse} no longer returns a security-sensitive value,
		which is incorrect behaviour.
\end{itemize}

\begin{lstlisting}[style=j, language=java, label={lst:computeSum},
caption={Example of leak through computeSum}]
result.add(computeSum(Collections.singletonList((int) i)));
\end{lstlisting}

\subsection{User interface}
The \code{enclavlow-plugin} Gradle submodule
is a Gradle plugin providing a task \code{:enclavlow},
which depends on the \code{:classes} builtin task
and performs flow analysis on the class binaries.
The analysis report is generated as HTML format at
\code{build/reports/enclavlow/index.html}
relative to the project on which task is invoked.
The report contains the following elements:

\paragraph{Method summary}
Each method defined in the downstream project (i.e. excluding libraries and Java stdlib)
is displayed with sensitive data that have passed through its parameters or return path.
If multiple invokations lead to different data flows,
the union of such data flows is displayed.

\paragraph{Redundant protection}
Methods detected to be run inside enclaves but never involved with any sensitive data
are highlighted in an index called "Redundant protection".
For each highlighted method, the developer
should mark it as \code{@JOCall} to run out of enclaves
or move its \code{@JECall} annotation to appropriate method calls,
or adjust the \code{@Source}/\code{@Sink} annotations.

\paragraph{Data leaks}
Methods which result in immediate data leaks,
such as methods passing security-sensitive data to other \code{@JOCall} methods
or methods marked \code{@JECall} returning/throwing security-sensitive data,
are highlighted in an index called "Data leaks".
For each highlighted method, the developer
should move it into enclave boundaries,
or adjust the \code{@Source}/\code{@Sink} annotations.

\subsection{Threat model}
The adversary of concern has privileged access to the host system,
including other threads in the JVM runtime, the JVM runtime itself,
other (root) processes, the operating system kernel,
the hypervisor, the BIOS and hardware such as the CPU and the RAM,
with the exception of the SGX execution part of the CPU.
Note that untrusted hardware cannot execute the enclave code
in the presence of cryptographically provable attestation performed with Uranus,
\cite{uranus},
so privileged access to the CPU does not imply privileged access to the SGX module.

Since all applications of interest are run on Uranus,
it is not meaningful to analyze threat models more capable than that as assessed by Uranus.
In particular, side channels such as timing attacks are not to be assessed.
\pname{} only studies attacks through at the data layer,
where the adversary has read and write access
to arbitrary data and instruction memory beyond SGX enclaves.


\section{Methodology}
The main component of this project is the analysis framework,
which is conducted in the form of iterations
to fulfill security policies as specified in the integration tests.
Other parts such as Gradle plugin interfae,
although necessary for usage,
are not focus areas of this project, and hence will not be discussed further.

\subsection{Design}
Since the adversary has arbitrary access to any untrusted memory and instruction,
the security policies of \pname{} differ slightly from typical information flow analysis.
For instance, the statement \code{a.b.c = d;} usually
does not propagte the effect of \code{d} to \code{a},
but since the adversary is capable of changing \code{b} to any memory location of its favour,
the security of this statement depends on whether \code{a} is trusted.

\subsubsection{Contract flow graph}
The approach adopted by \pname{} constructs a "contract flow graph" for each method analyzed.
The contract flow graph contains the following nodes:
\begin{itemize}
	\item "Static": Represents data located in static class fields
	\item "This": Represents the object on which a method was invoked
	\item "Param $x$": Each parameter is represented by a node
	\item "Return": Represents data flow through the return path
	\item "Throw": Represents data flow through the return path
	\item "@Source": Represents variables in the method explicitly declared as \code{@Source}
	\item "@Sink": Represents variables (or replaces the "Return" node) in the method explicitly declared as \code{@Sink}
	\item "Control": This is a special node representing how many times the function is called.
	\item "This", "Param $y$", "Return", "Throw" and "Control" from each function called from the current node
\end{itemize}

After all methods in a class are evaluated,
the contract graphs of child methods called from the analyzed methods
are lazily evaluated as well.
All contract graphs are merged into an aggregate flow graph,
joined using the function call nodes.

For the case of OOP polymorphism,
call graph analysis is performed to identify
the exact subclasses that could be passed.
In case multiple subclasses are possible,
their contract graphs are merged by taking the union of all flow edges.

See Figure \ref{fig:SourceSinkContract} for an example of aggregate flow graph,
with unconnected nodes omitted.

\begin{figure}
	\caption{Example contract flow graph for listing \ref{lst:SourceSinkExample}}
	\label{fig:SourceSinkContract}
	\begin{center}
		\digraph[scale=0.5]{contract}{
			getSumParam0[label = "getSum: param \#0"];
			parseParam0[label = "parse: param \#0"];
			parseReturn[label = "parse: return"];
			computeSumParam0[label = "computeSum: param \#0"];
			computeSumReturn[label = "computeSum: return"];
			getSumParam0 -> parseParam0;
			parseParam0 -> parseReturn;
			"@Source" -> parseReturn;
			parseReturn -> computeSumParam0;
			computeSumParam0 -> computeSumReturn;
			computeSumReturn -> "@Sink";
			}
	\end{center}
\end{figure}

\subsubsection{Local flow graph}
To construct the contract flow graph,
a local graph is constructed with each local variable being a "private node"
in addition to the default nodes.
The analysis follows along the control flow of the program,
performing the \emph{consume}, \emph{branch} and \emph{merge} operations.

The \emph{consume} operation consumes statements in form of 3AC \cite{sootsurvivor}.
Every step adds or removes some flow edges,
as described exhaustively in Table \ref{table:tac}.
The relationship between the graph and the "lvalue"/"rvalue" terminology
in Table \ref{table:tac} are explained in Table \ref{table:lrvalue}.

The \emph{branch} operation performs a deep clone of the local flow graph
and continues following each branch with its clone.

The \emph{merge} operation pops the uppermost control flow node from the graph,
and takes the union of all flows from each branched graph.

Note that the control flow stack is always pushed from a conditional instruction
before splitting into branches,
which is important for attacks that count the number of times a method was called,
hence inferring the sensitive value that determined the branch halting problem.

\begin{table}
	\caption{3AC instructions affecting local flow graph}
	\centering
	\begin{tabular}{|c|l|}
		\hline
		\textbf{Instruction type} & \textbf{Effects on local flow graph}
		\\ \hline
		\multirow3*{Assignment} & "Control" flows to lvalue nodes of destination. \\
		& Erases current connections to lvalue nodes of destination. \\
		& rvalue nodes of source flow to lvalue nodes of destination.
		\\ \hline
		\multirow2*{Return} & "Control" flows to "Return" node. \\
		& rvalue nodes of returned value flow to "Return" node.
		\\ \hline
		\multirow2*{Throw} & "Control" flows to "Throw" node. \\
		& rvalue nodes of thrown value leaks to "Throw" node.
		\\ \hline
		\multirow3*{Conditional (If/Switch)}
		& A new "Control" node is pushed to the control stack. \\
		& Previous "Control" flows to the new "Control". \\
		& rvalue nodes of predicate leaks to the new "Control".
		\\ \hline
	\end{tabular}
	\label{table:tac}
\end{table}

\begin{table}
	\caption{lvalue and rvalue nodes for expressions}
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		\textbf{Expression type} & \textbf{lvalue nodes} & \textbf{rvalue nodes}
		\\ \hline
		Binary operations & Unreachable & Union of rvalues from operands
		\\ \hline
		Array literal \code{new int[a]} & \multirow2*{Unreachable}
		& \multirow2*{Union of rvalues from count or literal elements} \\
		or \code{new int[]\{a\}} & &
		\\ \hline
		Array access \code{a[b]} & lvalues of \code a & rvalues of \code a and \code b
		\\ \hline
		Instance access \code{a.b} & lvalues of \code a & rvalues of \code a
		\\ \hline
		Static access \code{Class.field} & "Static" & none
		\\ \hline
		Parameter & the parameter node & the parameter node
		\\ \hline
		Local variable & its own dedicated node & its own dedicated node
		\\ \hline
		\code{this} & "This" & "This"
		\\ \hline
		Class cast and instanceof & lvalues of the underlying value & rvalues of the underlying value
		\\ \hline
		Method/constructor call & "Return" of the called method & "Return" of the called method
		\\ \hline
	\end{tabular}
	\label{table:lrvalue}
\end{table}


\subsection{System Requirements}
The logical code of this project is mostly implemented in Kotlin,
a JVM language with more concise syntax than Java.
However, to ensure that he behaviour analyzed
is as explicit as possible,
all test cases are written in Java.

As Uranus was only tested against Linux systems,
this project does not intend to support other operating systems.
Furthermore, due to classpath detection difficulties,
only OpenJDK Version 8 and 11 are supported currently.
Nevertheless, since \pname{} is just a developer tool,
its runtime is actually independent of that targeted by Uranus,
so it is possible to test support for those frameworks in the future.

\pname{} is packaged as a Gradle plugin,
allowing developers to use it with Gradle Version 6.
However, the \code{enclavlow-core} subproject can be reused in other contexts,
such as Maven plugins, IDE plugins, etc.

\subsection{Flow analysis framework}
Soot \cite{sootsurvivor} was selected as the framework for conducting flow analysis.
Although multiple existing flow analysis systems using Soot alrady exist,
they are not designed against SGX enclave protection,
but \pname{} adopts more strict security policies
to prevent attacks from more privileged attackers,
unlike traditional information flow analysis
that mostly detects user input as the source of insecurity.

Soot takes Java bytecode files (\code{*.class}) as input
and compiles them into a 3AC language called Jimple,
which simplifies analysis work.
The consume-branch-merge approach mentioned in the last subsection
was inspired by the forward flow analysis interface in Jimple.

Other flow analysis frameworks were also considered,
such as Joana \cite{joana} and JFlow \cite{jflow}.
Soot was chosen due to its distinctively thorough documentation
and builtin support for call graph analysis.

\subsection{Testing}
This project uses JUnit 5 and \code{kotlin.test} framework
to conduct both unit and integration tests.
Test case classes are compiled together in the \code{:core:testClasses} task,
which declares compile-time dependency on the API \code{@Source} and \code{@Sink} annotations.

\section{Results and Discussion}
\subsection{Difficulties and Limitations}
The principles of OOP imply that a method called may be swapped with another subclass
that performs different actions than the current one.
Although Uranus prevents the adversary
from passing arbitrary malicious code into the enclave memory,
it is still possible to pass obejcts of unexpected subclass
through the \code{@JEcall} boundary.
Consider listing \ref{lst:oop} for example.
If \code{cs} is passed with a \code{substr} implementation
that writes its parameters to a static variable,
the function would leak the length of the security-sensitive secret,
which is not desirable.
To correctly solve the vulnerability of OOP substitution,
it is necessary to perform call graph analysis on the actual classes passed to the method,
which involves more complex framework level work.

\begin{lstlisting}[style=j, language=java, label={lst:oop},
caption={Example attack through OOP substitution}]
@JECall
public void foo(CharSequence cs) {
	@Source byte[] secret = getSecret();
	writeEncrypted(cs.substr(secret.length()));
}
\end{lstlisting}

Despite optimizations and simplifications,
it is still not possible to perform 100\% accurate information flow analysis
within efficient time complexity \cite{SmithGeoffrey2007PoSI}.
For example, this project merges conditional branches together
by taking the union of flow graphs,
resulting in easy false positive rates.
Listing \ref{lst:falsepositives} enumerates a number of false positives
incorrectly identified by \pname{},
which are not going to be fixed because of the unlikeness of use.

\begin{lstlisting}[style=j, language=java, label={lst:falsepositives}]
int foo() {
	@Source boolean secret = getSecret();
	if(secret) {
		return 1;
	} else {
		return 1;
		}
}

class Ref<T> { T t; }
Ref<String> bar() {
	Ref<String> ref = new Ref<>();
	@Source String secret = getSecret();
	ref.t = secret;
	ret.t = "";
	return ret;
}
\end{lstlisting}

It is also impossible to analyze further than the JNI level,
since analyzing across JNI boundary implies
the need to interact with a native analysis tool,
which is entirely out of scope of this project.
Since Uranus effectively denies system calls,
a GIGO assumption can be made on JNI calls.

At the technical aspect,
multiple technical challenges were encountered when using Soot.
Since Soot was designed to be a command line tool,
it does not support direct calling from other environments very well.
In particular, the entrypoint of Soot API is the \code{soot.Main.main()} method,
which is the standard CLI interface in Java.
As a result, extra time is spent on clearing global states used by Soot.
Furthermore, due to restrictions in the Soot framework,
each tested Java method must be run in a separate JVM,
resulting in poor testing performance.

\subsection{Future work}
\pname{} will be tested against common libraries in the Java ecosystem
to identify common use cases that cannot be correctly identified,
and to test the scalability of the software.
Since it is necessary for \pname{} to perform upstream analysis
to identify the contract flow graphs for the functions called from the user project,
performance with common libraries is crucial for the usability of the tool.
Furthermore, formal study will be performed to investigate
which exact cases with which \pname{} would identify false positives
to reduce the undefined nature of the tool.

\section{Conclusion}
This project aims to develop a JVM code analysis tool
for software using Uranus for SGX applications
to assist the choice of enclave boundaries.
A divide-and-conquer approach was adopted for
efficient abstraction of information flow across a method.
Since the project delivers an analysis tool
but leaves the decision right to the user,
a higher tolerance for false positives was accepted.

To formalize the behaviour of false positives with the project,
analysis is to be conducted on the occurrence of false positives.
Usability of the tool with common libraries in the Java ecosystem will be assessed.
With sufficient theoretical background to support the correctness of the algorithms,
this tool is expected to serve as an auxiliary quality control integration
for open source projects that may see demand in the big data industry
and other confidential data processing applications.

\newpage
\addcontentsline{toc}{section}{References}
\bibliographystyle{acm}
\bibliography{cite.bib}{}

\end{document}
